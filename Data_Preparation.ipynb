{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "db_name = 'Source/dblp.db'\n",
    "conn = sqlite3.connect(db_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('unique.pickle' , 'rb') as file:\n",
    "    unique=pickle.load(file)\n",
    "with open ('indices.pickle' , 'rb') as file:\n",
    "    indices=pickle.load(file)\n",
    "    \n",
    "with open ('author_abbvs.pickle' , 'rb') as file:\n",
    "    author_abbvs=pickle.load(file)\n",
    "    \n",
    "with open ('Source/index2auth.pickle' , 'rb') as file:\n",
    "    authors=pickle.load(file)\n",
    "    \n",
    "    \n",
    "    \n",
    "with open('Source/x_train.pickle','rb') as file:\n",
    "    x_train=pickle.load(file)\n",
    "with open('Source/y_train.pickle','rb') as file:\n",
    "    y_train=pickle.load(file)\n",
    "with open('Source/x_test.pickle','rb') as file:\n",
    "    x_test=pickle.load(file)\n",
    "with open('Source/y_test.pickle','rb') as file:\n",
    "    y_test=pickle.load(file)\n",
    "with open('Source/x_validate.pickle','rb') as file:\n",
    "    x_validate=pickle.load(file)\n",
    "with open('Source/y_validate.pickle','rb') as file:\n",
    "    y_validate=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of authors per variation:\n",
    "n=[len(x) for x in indices]  #each element represents the number of authors shared by the respective name variante\n",
    "s= sorted(range(len(n)), key=lambda k: n[k], reverse=True)    #indices of n sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exst=True\n",
    "i=0\n",
    "while ((exst == True)  and (i<len(s))):\n",
    "    model_version=s[i]  #the next untrained model of the name with highest number of authors \n",
    "    task='task_'+str(model_version)+'.pickle'\n",
    "    exst=os.path.exists(\"Training/Tasks/\"+task)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue . . .\n"
     ]
    }
   ],
   "source": [
    "if i>len(s):\n",
    "    print ('all done . . . ')  #all tasks for all author names have been created \n",
    "else: \n",
    "    print ('Continue . . .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author idx who have the same variante\n",
    "authors_idex=indices[model_version]\n",
    "all_authors=[authors[idx] for idx in authors_idex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for auth in all_authors:\n",
    "    query='SELECT combination_id FROM reference WHERE target_author= \"'+auth+'\";'\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    tmp2 = cursor.fetchall()\n",
    "    a.extend(tmp2)\n",
    "    cursor.close()\n",
    "new_x=[b[0] for b in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_version=1519374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get new dataset\n",
    "vector_id=np.in1d(np.array(x_train), new_x)#.nonzero()[0]  #get indices in the vector \n",
    "vector_id=np.where(vector_id==True)[0]\n",
    "final_x=np.array(x_train)[vector_id]  #comb ID\n",
    "final_y=np.array(y_train)[vector_id]   #do not forget to change the order from 0 to n\n",
    "#num_ref_15= int((15*len(final_x))/70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert old IDS to new ones from 0 to number of authors\n",
    "(old_authors_ids, counts) = np.unique(final_y, return_counts=True)\n",
    "new_authors_ids=range(0,len(old_authors_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train2=[new_authors_ids[old_authors_ids.index(a)] for a in final_y]\n",
    "#much faster\n",
    "d=[[a,np.where(final_y==old_authors_ids[a])[0]] for a in range(len(old_authors_ids))]\n",
    "y_train2=np.zeros(len(final_y))\n",
    "for a in d:\n",
    "    y_train2[a[1]]=new_authors_ids[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new and old ids to change testdata \n",
    "\n",
    "with open('Training/Miscs/new_authors_ids_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(new_authors_ids, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Miscs/old_authors_ids_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(old_authors_ids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_authors_ids=list(old_authors_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x, y_train2 = zip(*sorted(zip(final_x, y_train2)))\n",
    "y_train2=[int(i) for i in y_train2]\n",
    "final_x=np.array(final_x)\n",
    "\n",
    "# save new training set \n",
    "with open('Training/Data/y_train_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_train_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "ind=np.intersect1d(old_authors_ids, y_validate) #get authors that are present in train set (basically old authors ids)\n",
    "vector_id=np.in1d(np.array(y_validate), ind).nonzero()[0]  #get indices in the vector \n",
    "final_x_val=np.array(x_validate)[vector_id]  #comb ID\n",
    "final_y_val=np.array(y_validate)[vector_id]   #do not forget to change the order from 0 to n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25214"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_ref_15\n",
    "len(final_x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# go for the simpliest solution \\ntry:\\n    vector_id=random.sample(range(len(final_x_val)), num_ref_15)\\n    final_x_val=np.array(final_x_val)[vector_id]  #comb ID\\n    final_y_val=np.array(final_y_val)[vector_id]   #do not forget to change the order from 0 to n\\nexcept: \\n    pass\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# go for the simpliest solution \n",
    "try:\n",
    "    vector_id=random.sample(range(len(final_x_val)), num_ref_15)\n",
    "    final_x_val=np.array(final_x_val)[vector_id]  #comb ID\n",
    "    final_y_val=np.array(final_y_val)[vector_id]   #do not forget to change the order from 0 to n\n",
    "except: \n",
    "    pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_valid2=[new_authors_ids[old_authors_ids.index(a)] for a in final_y_val]\n",
    "\n",
    "d=[[a,np.where(final_y_val==old_authors_ids[a])[0]] for a in range(len(old_authors_ids))]\n",
    "y_valid2=np.zeros(len(final_y_val))\n",
    "for a in d:\n",
    "    y_valid2[a[1]]=new_authors_ids[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_val, y_valid2 = zip(*sorted(zip(final_x_val, y_valid2)))\n",
    "y_valid2=[int(i) for i in y_valid2]\n",
    "final_x_val=np.array(final_x_val)\n",
    "\n",
    "\n",
    "# save new validation set \n",
    "with open('Training/Data/y_validate_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_valid2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_validate_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_x_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "ind=np.intersect1d(old_authors_ids, y_test) #get authors that are present in train set (basically old authors ids)\n",
    "vector_id=np.in1d(np.array(y_test), ind).nonzero()[0]  #get indices in the vector \n",
    "final_x_test=np.array(x_test)[vector_id]  #comb ID\n",
    "final_y_test=np.array(y_test)[vector_id]   #do not forget to change the order from 0 to n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# go for the simpliest solution \\ntry:\\n    vector_id=random.sample(range(len(final_x_test)), num_ref_15)\\n    final_x_test=np.array(final_x_test)[vector_id]  #comb ID\\n    final_y_test=np.array(final_y_test)[vector_id]   #do not forget to change the order from 0 to n\\nexcept:\\n    pass\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# go for the simpliest solution \n",
    "try:\n",
    "    vector_id=random.sample(range(len(final_x_test)), num_ref_15)\n",
    "    final_x_test=np.array(final_x_test)[vector_id]  #comb ID\n",
    "    final_y_test=np.array(final_y_test)[vector_id]   #do not forget to change the order from 0 to n\n",
    "except:\n",
    "    pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test2=[new_authors_ids[old_authors_ids.index(a)] for a in final_y_test]\n",
    "d=[[a,np.where(final_y_test==old_authors_ids[a])[0]] for a in range(len(old_authors_ids))]\n",
    "y_test2=np.zeros(len(final_y_test))\n",
    "for a in d:\n",
    "    y_test2[a[1]]=new_authors_ids[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_test, y_test2 = zip(*sorted(zip(final_x_test, y_test2)))\n",
    "y_test2=[int(i) for i in y_test2]\n",
    "final_x_test=np.array(final_x_test)\n",
    "\n",
    "\n",
    "\n",
    "# save new test set \n",
    "with open('Training/Data/y_test_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_test_new_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_x_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (conn):\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Training/Tasks/task_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_version, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_version=1520689\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load train, test and validation daataset\n",
    "#with tf.device('/gpu:0'):\n",
    "with open('Training/Miscs/new_authors_ids_'+str(model_version)+'.pickle','rb') as file:\n",
    "    new_authors_ids=pickle.load(file)\n",
    "with open('Training/Miscs/old_authors_ids_'+str(model_version)+'.pickle','rb') as file:\n",
    "    old_authors_ids=pickle.load(file)\n",
    "with open('Training/Data/x_train_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    x_train=pickle.load(file)\n",
    "with open('Training/Data/y_train_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    y_train=pickle.load(file)\n",
    "with open('Training/Data/x_validate_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    x_validate=pickle.load(file)\n",
    "with open('Training/Data/y_validate_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    y_validate=pickle.load(file)\n",
    "    \n",
    "with open('Training/Data/x_test_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    x_test=pickle.load(file)\n",
    "with open('Training/Data/y_test_new_'+str(model_version)+'.pickle','rb') as file:\n",
    "    y_test=pickle.load(file)\n",
    "with open('Source/auth2index.pickle','rb') as file:\n",
    "    auth2index=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123312"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'Source/dblp.db'\n",
    "conn = sqlite3.connect(db_name) \n",
    "\n",
    "def dict_factory(cursor, row):\n",
    "    d = {}\n",
    "    for idx, col in enumerate(cursor.description):\n",
    "        d[col[0]] = row[idx]\n",
    "    return d\n",
    "\n",
    "\n",
    "zipped_lists = zip(x_train, y_train)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "sorted_list1 = [(x_train.append(aa), y_train.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "conn.row_factory = dict_factory\n",
    "query = \"SELECT * FROM reference WHERE combination_id in \"+str(tuple(x_train))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "records_train = cursor.fetchall()\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25214"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_lists = zip(x_validate, y_validate)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "x_validate=[]\n",
    "y_validate=[]\n",
    "sorted_list1 = [(x_validate.append(aa), y_validate.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "\n",
    "\n",
    "conn.row_factory = dict_factory\n",
    "query = \"SELECT * FROM reference WHERE combination_id in \"+str(tuple(x_validate))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "records_validate = cursor.fetchall()\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26238"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zipped_lists = zip(x_test, y_test)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "sorted_list1 = [(x_test.append(aa), y_test.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "\n",
    "conn.row_factory = dict_factory\n",
    "query = \"SELECT * FROM reference WHERE combination_id in \"+str(tuple(x_test))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "records_test = cursor.fetchall()\n",
    "cursor.close()\n",
    "if (conn):\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_author=[]\n",
    "ref_ref=[]\n",
    "ref_year=[]\n",
    "for record in records_train:\n",
    "    ref_ref.append(tuple(record.values())[1])\n",
    "    ref_year.append(int(tuple(record.values())[8]))\n",
    "for record in records_validate:\n",
    "    ref_ref.append(tuple(record.values())[1])\n",
    "    ref_year.append(int(tuple(record.values())[8]))\n",
    "for record in records_test:\n",
    "    ref_ref.append(tuple(record.values())[1])\n",
    "    ref_year.append(int(tuple(record.values())[8]))\n",
    "X=np.concatenate((x_train,x_validate,x_test))\n",
    "Y=np.concatenate((y_train,y_validate,y_test))\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174764"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w=np.unique(Y)\n",
    "ref_ref=np.array(ref_ref)\n",
    "ref_year=np.array(ref_year)\n",
    "n_x_train=[]\n",
    "n_y_train=[]\n",
    "n_x_validate=[]\n",
    "n_y_validate=[]\n",
    "n_x_test=[]\n",
    "n_y_test=[]\n",
    "\n",
    "tt=[]\n",
    "tt2=[]\n",
    "tt3=[]\n",
    "for i in range(len(w)):\n",
    "    tmp=np.where(Y==w[i])[0]\n",
    "    tmp2=ref_ref[tmp]\n",
    "    tmp3=np.unique(tmp2)\n",
    "    \n",
    "    '''\n",
    "    tmp22=ref_year[tmp]\n",
    "    tmp3,tmp30=np.unique(tmp2,return_index=True)\n",
    "    tmp33=tmp22[tmp30]\n",
    "    tmp0=np.argsort(tmp33)\n",
    "    tmp3=tmp3[tmp0]\n",
    "    tmp33=tmp33[tmp0]\n",
    "    '''\n",
    "    \n",
    "    tp=int(0.7*len(tmp3))   # # traing samples\n",
    "    tp=tp if tp>0 else 1\n",
    "    vp=int(0.5*(len(tmp3)-tp))   # # validation samples\n",
    "    random.shuffle(tmp3)\n",
    "    tmp4=tmp3[:tp]\n",
    "    tmp5=np.where(np.isin(ref_ref,tmp4))[0]\n",
    "    tmp5=np.intersect1d(tmp5,tmp)\n",
    "    if len(tmp5)<1:\n",
    "        print ('stop')\n",
    "        break\n",
    "    #break\n",
    "    n_x_train.extend(X[tmp5])\n",
    "    n_y_train.extend(Y[tmp5])\n",
    "    tt.extend(ref_ref[tmp5])\n",
    "    \n",
    "    tmp4=tmp3[tp:tp+vp]\n",
    "    tmp5=np.where(np.isin(ref_ref,tmp4))[0]\n",
    "    tmp5=np.intersect1d(tmp5,tmp)\n",
    "    n_x_validate.extend(X[tmp5])\n",
    "    n_y_validate.extend(Y[tmp5])\n",
    "    tt2.extend(ref_ref[tmp5])\n",
    "    \n",
    "    tmp4=tmp3[tp+vp:]\n",
    "    tmp5=np.where(np.isin(ref_ref,tmp4))[0]\n",
    "    tmp5=np.intersect1d(tmp5,tmp)\n",
    "    n_x_test.extend(X[tmp5])\n",
    "    n_y_test.extend(Y[tmp5])\n",
    "    tt3.extend(ref_ref[tmp5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_lists = zip(n_x_train, n_y_train)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "n_x_train=[]\n",
    "n_y_train=[]\n",
    "sorted_list1 = [(n_x_train.append(aa), n_y_train.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "\n",
    "zipped_lists = zip(n_x_test, n_y_test)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "n_x_test=[]\n",
    "n_y_test=[]\n",
    "sorted_list1 = [(n_x_test.append(aa), n_y_test.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "zipped_lists = zip(n_x_validate, n_y_validate)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "n_x_validate=[]\n",
    "n_y_validate=[]\n",
    "sorted_list1 = [(n_x_validate.append(aa), n_y_validate.append(bb)) for aa, bb in sorted_zipped_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Training/Data/y_test_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_y_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_test_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_x_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('Training/Data/y_train_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_y_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_train_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_x_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('Training/Data/y_validate_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_y_validate, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Training/Data/x_validate_new_reshuffeled_'+str(model_version)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(n_x_validate, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=-2\n",
    "print (records_train[v])\n",
    "print (x_train[v])\n",
    "\n",
    "print (records_test[v])\n",
    "print (x_test[v])\n",
    "\n",
    "print (records_validate[v])\n",
    "print (x_validate[v])\n",
    "\n",
    "n_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some test that you can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_version=1520908\n",
    "import pickle5 as pickle\n",
    "import sqlite3\n",
    "\n",
    "with open('Training/Data/y_test_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    y_test=pickle.load(handle)\n",
    "with open('Training/Data/x_test_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    x_test=pickle.load(handle)\n",
    "    \n",
    "with open('Training/Data/y_train_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    y_train=pickle.load(handle)\n",
    "with open('Training/Data/x_train_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    x_train=pickle.load(handle)\n",
    "    \n",
    "with open('Training/Data/y_validate_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    y_validate=pickle.load(handle)\n",
    "with open('Training/Data/x_validate_new_reshuffeled_'+str(model_version)+'.pickle', 'rb') as handle:\n",
    "    x_validate=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(np.unique(X)))\n",
    "print(len(n_x_test))\n",
    "print(len(n_x_train))\n",
    "print(len(n_x_validate))\n",
    "n_x=np.concatenate((n_x_train,n_x_validate,n_x_test))\n",
    "n_y=np.concatenate((n_y_train,n_y_validate,n_y_test))\n",
    "\n",
    "'''\n",
    "db_name = '../../../data/Bib2Auth/data1.db'\n",
    "conn = sqlite3.connect(db_name) \n",
    "\n",
    "def dict_factory(cursor, row):\n",
    "    d = {}\n",
    "    for idx, col in enumerate(cursor.description):\n",
    "        d[col[0]] = row[idx]\n",
    "    return d\n",
    "\n",
    "\n",
    "zipped_lists = zip(n_x_train, n_y_train)\n",
    "sorted_zipped_lists = sorted(zipped_lists)\n",
    "n_x_train=[]\n",
    "n_y_train=[]\n",
    "sorted_list1 = [(n_x_train.append(aa), n_y_train.append(bb)) for aa, bb in sorted_zipped_lists]\n",
    "\n",
    "conn.row_factory = dict_factory\n",
    "query = \"SELECT * FROM reference WHERE combination_id in \"+str(tuple(n_x_train))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "records = cursor.fetchall()\n",
    "cursor.close()\n",
    "if (conn):\n",
    "    conn.close()\n",
    "for record in records:\n",
    "    tt.append(tuple(record.values())[1])\n",
    "\n",
    "'''\n",
    "n_tt=np.concatenate((tt,tt2,tt3))\n",
    "a,b=np.unique(n_tt,return_counts=True)\n",
    "print(a)\n",
    "print (b)\n",
    "c=np.where(b>1)[0]\n",
    "print(c)\n",
    "d=a[c]\n",
    "e=np.where(np.isin(n_x,d))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tt=np.concatenate((tt,tt2,tt3))\n",
    "a,b=np.unique(n_tt,return_counts=True)\n",
    "\n",
    "\n",
    "d0=0   #two authors\n",
    "\n",
    "d1=0   #three authors\n",
    "for aa in a:\n",
    "    x=np.where(n_tt==aa)[0]\n",
    "    x2=n_y[x]\n",
    "    x3=np.unique(x2)\n",
    "    if len(x3)>1:\n",
    "        d0+=1\n",
    "    if len(x3)>2:\n",
    "        d1+=1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0.\n",
    "en(np.unique(n_x[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=e[0]\n",
    "print (n_tt[p])\n",
    "print (n_x[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tt=np.array(n_tt)\n",
    "len(np.unique(n_tt[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt=np.unique(tt[e])\n",
    "ttt[-1]\n",
    "#np.where(tt==4825)\n",
    "#n_x_train[[36951, 36952, 36953, 36954]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(n_x_train==n_x_train[c[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=n_x_train[e]\n",
    "ee=np.where(np.isin(X,d))[0]\n",
    "f=ref_ref[ee]\n",
    "len(np.unique(f))\n",
    "l=0\n",
    "g=[]\n",
    "for i in ee:\n",
    "    record=records_train[i]\n",
    "    if (tuple(record.values())[3]==tuple(record.values())[5])&(tuple(record.values())[4]==tuple(record.values())[6]):\n",
    "        l+=1\n",
    "        g.append(tuple(record.values())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.unique(g,return_counts=True)\n",
    "d=np.where(b>2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.where(ref_ref==5069)[0]\n",
    "Y[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_train[a[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=np.where(Y==1566)[0]\n",
    "tmp2=ref_ref[tmp]\n",
    "tmp3=np.unique(tmp2)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.unique(w,return_counts=True)\n",
    "print (a)\n",
    "print (b)\n",
    "np.where(b>1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "b=[5,1,2,1,3,1,5,4]\n",
    "np.where(np.isin(b,a))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
